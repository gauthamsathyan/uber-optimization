{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c8ef79",
      "metadata": {
        "id": "b6c8ef79"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1204bbaa",
      "metadata": {
        "id": "1204bbaa"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('uber_review.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd04eff9",
      "metadata": {
        "id": "fd04eff9"
      },
      "outputs": [],
      "source": [
        "# Truncate overly long reviews\n",
        "max_input_length = 512  # Maximum input length for BERT\n",
        "df['Comment'] = df['Comment'].apply(lambda x: x[:max_input_length])\n",
        "\n",
        "# First, you need to convert the category labels into numerical format\n",
        "label_encoder = LabelEncoder()\n",
        "df['CategoryLabel'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "# One-hot encode the labels\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "one_hot_labels = one_hot_encoder.fit_transform(df['CategoryLabel'].values.reshape(-1, 1))\n",
        "\n",
        "# Split the dataset into train and test set\n",
        "train_text, test_text, train_labels, test_labels = train_test_split(\n",
        "    df['Comment'], one_hot_labels, random_state=2018, test_size=0.3\n",
        ")\n",
        "\n",
        "# Initialize the BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = TFBertForSequenceClassification.from_pretrained(\n",
        "    'bert-base-uncased', num_labels=len(label_encoder.classes_)\n",
        ")\n",
        "\n",
        "# Tokenize the text\n",
        "train_encodings = tokenizer(train_text.tolist(), truncation=True, padding=True, max_length=max_input_length)\n",
        "test_encodings = tokenizer(test_text.tolist(), truncation=True, padding=True, max_length=max_input_length)\n",
        "\n",
        "# Prepare the data inputs\n",
        "train_inputs = {\n",
        "    'input_ids': tf.convert_to_tensor(train_encodings['input_ids']),\n",
        "    'attention_mask': tf.convert_to_tensor(train_encodings['attention_mask']),\n",
        "    'labels': tf.convert_to_tensor(train_labels)\n",
        "}\n",
        "test_inputs = {\n",
        "    'input_ids': tf.convert_to_tensor(test_encodings['input_ids']),\n",
        "    'attention_mask': tf.convert_to_tensor(test_encodings['attention_mask']),\n",
        "    'labels': tf.convert_to_tensor(test_labels)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef5589c",
      "metadata": {
        "id": "4ef5589c",
        "outputId": "84e95a9f-a67e-4e12-cf77-fd4fe4a2e291",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "103/103 [==============================] - 2634s 25s/step - loss: 0.4653 - accuracy: 0.8039\n",
            "Epoch 2/2\n",
            "103/103 [==============================] - 2580s 25s/step - loss: 0.1656 - accuracy: 0.9574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dc2c45d50>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Compile and train the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5), loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "model.fit([train_inputs['input_ids'], train_inputs['attention_mask']], train_inputs['labels'], epochs=2, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e87d244",
      "metadata": {
        "id": "0e87d244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89a66c54-fe0c-42f2-a086-1332ca38bdb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We're sorry to hear about your experience. We take your safety seriously and will review your complaint as soon as possible.\n"
          ]
        }
      ],
      "source": [
        "# Define the prediction and response generation functions\n",
        "def predict_category(complaint):\n",
        "    encoding = tokenizer(complaint, truncation=True, padding=True, max_length=max_input_length, return_tensors='tf')\n",
        "    output = model(encoding)\n",
        "    category_label = tf.argmax(output.logits, axis=-1).numpy()[0]\n",
        "    return label_encoder.classes_[category_label]\n",
        "\n",
        "def automated_response(complaint):\n",
        "    category = predict_category(complaint)\n",
        "    if category == 'driver_issues':\n",
        "        return \"We're sorry to hear about your experience. We take your safety seriously and will review your complaint as soon as possible.\"\n",
        "    elif category == 'account_issues':\n",
        "        return \"We're sorry to hear about your account issues. Please change your password immediately and contact our security team.\"\n",
        "    else:\n",
        "        return \"Thank you for your feedback. We will review your complaint and get back to you soon.\"\n",
        "\n",
        "# Test the prediction and response generation\n",
        "complaint = \"I had a terrible experience with the driver...\"\n",
        "response = automated_response(complaint)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4de5f4",
      "metadata": {
        "id": "ac4de5f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "55737c82-a907-4bb3-fb5a-25137278dc5d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'driver_issues'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "predict_category(complaint)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}